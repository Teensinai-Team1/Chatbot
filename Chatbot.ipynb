{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot to help in communication between refugees and personnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am importing the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import io\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the file with the info for chatbot to give."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('details.txt')\n",
    "raw = f.read().lower()\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "sent_tokens = nltk.sent_tokenize(raw) #Puts each sentence of paragraph into a list/array\n",
    "word_tokens = nltk.word_tokenize(raw) #Puts each word of a sentence into a list/array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greetings database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_GREETINGS = ('hello', 'hi', 'hey', 'greetings', 'good morning')\n",
    "BOT_GREETINGS = [\"hi\", \"hey\", \"hello\", \"nice to meet you\", \"hi what's up\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in USER_GREETINGS:\n",
    "            return random.choice(BOT_GREETINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(user_input):\n",
    "    chatbot_response = ''\n",
    "    sent_tokens.append(user_input)\n",
    "    Vec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
    "    tfidf = Vec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if req_tfidf == 0:\n",
    "        chatbot_response = chatbot_response + \"\"\"Sorry I don't understand\"\"\"\n",
    "        return chatbot_response\n",
    "    else:\n",
    "        chatbot_response = chatbot_response + sent_tokens[idx]\n",
    "        return chatbot_response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running = True\n",
    "print(\"Hello I am Team 1's chatbot version 0.1, type 'bye' to exit\")\n",
    "\n",
    "reports = list()\n",
    "\n",
    "while running:\n",
    "    print(\"\")\n",
    "    print(\"\"\"Push '1' or 'report' to file a complaint.\"\"\")\n",
    "    print(\"\"\"Push '2' or 'info' to get info on the camp.\"\"\")\n",
    "    print(\"\"\"Push '3' or 'survey' to fill in the latest survey\"\"\")\n",
    "    user_input = input().lower()\n",
    "    if user_input != \"bye\":\n",
    "        if user_input == \"thanks\" or user_input == \"thank you\":\n",
    "            running = False\n",
    "            print(\"\"\"Bot: You're welcome\"\"\")\n",
    "            \n",
    "        elif user_input == \"1\" or user_input == \"report\":\n",
    "            myreport = input(\"Please describe the issue: \")\n",
    "            reports.append(myreport)\n",
    "            print(\"Thank you for the feedback. The authorities will be informed that: %s and will be acted upon\" %myreport)\n",
    "        elif user_input == \"2\" or user_input == \"info\":\n",
    "            question = input(\"Please ask anything about the camp: \").lower()\n",
    "            if greeting(question) != None:\n",
    "                print(\"Chatbot: \"+ greeting(user_input))\n",
    "            else:\n",
    "                print(\"Chatbot: \", end=\"\")\n",
    "                print(respond(question))\n",
    "                sent_tokens.remove(question)\n",
    "        elif user_input == \"3\" or user_input == \"survey\":\n",
    "            print(\"Work in Progress\")\n",
    "        else:\n",
    "            if greeting(user_input) != None:\n",
    "                print(\"Chatbot: \"+ greeting(user_input))\n",
    "            else:\n",
    "                print(\"Chatbot: \", end=\"\")\n",
    "                print(respond(user_input))\n",
    "                sent_tokens.remove(user_input)\n",
    "    else:\n",
    "        running = False\n",
    "        print(\"Chatbot: Bye, have a nice day.\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
